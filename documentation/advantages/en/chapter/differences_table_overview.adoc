=== Tabular Comparison ({application}, MS Copilot, ChatGPT (Standalone))

ifeval::[{arc-assist} == 1]
===== Strategic Focus & Professional Orientation

|===
|Criterion |{application} |MS Copilot|ChatGPT (Standalone)

|Basic orientation |Specialized solution for Internal Audit |Productivity suite in the MS ecosystem |General AI dialog platform
|Focus on Internal Audit |Yes, throughout |No, only generic functions |No, only generic functions
|Professionally curated use cases| Yes, by {author} |No |No
|Support for the entire audit cycle |Yes (risk assessment to action tracking) |Only indirectly via user prompts |Only indirectly via user prompts
|===
endif::[]

===== LLM Selection & Vendor Independence

|===
|Criterion |{application} |MS Copilot|ChatGPT (Standalone)

|Supported LLM providers |Multiple: e.g. OpenAI via Azure, AWS Bedrock, open-source/self-hosted models |Primarily Microsoft / Azure |OpenAI (possibly plus a few partner integrations)
|Vendor independence |High – free choice and combination of different providers|Low – tightly bound to Microsoft stack |Low – tied to OpenAI ecosystem
|Switch to European LLMs| Yes, e.g. Mistral |Only if MS offers them |Only if OpenAI offers corresponding models
|Fallback for outages |Yes, switching to alternative LLMs possible |Rather no, dependent on Azure/Microsoft |Rather no, dependent on OpenAI
|===

===== Operational Model & Data Sovereignty

|===
|Criterion |{application} |MS Copilot|ChatGPT (Standalone)

|Operational model |On-premise in customer infrastructure |Cloud-based (Microsoft Cloud/Azure) |Cloud-based (OpenAI)
|Data storage |In the customer's own data center|In the provider’s cloud |In the provider’s cloud
|Data sovereignty| Fully with the customer |Dependent on cloud contracts and region |Dependent on OpenAI contracts and region
|Suitability for highly sensitive data |Very high (on-premise, role-based RAG) |Limited, depending on compliance requirements |Limited, usually not for highly regulated areas
|===

===== User Experience & Entry Barrier

|===
|Criterion |{application} |MS Copilot|ChatGPT (Standalone)

|Classic chat interface |Yes (incl. voice input & document upload) |Yes, integrated in the Office context |Yes
|Form-based use cases

|Yes, ready-made forms for customer
ifeval::[{arc-assist} == 1]
audit-
endif::[]
use cases

|No |No
|Need for prompting know-how| Low – standard use cases usable via forms |Medium – quality highly depends on prompts |Medium to high – pure prompt usage
|Standardization of results|High – central system prompts and use case templates |Low – individual usage|Low – individual usage
|Star rating for use cases|Yes (quality feedback integrated) |No|No

|Transfer of
ifeval::[{arc-assist} == 1]
audit-
endif::[]
use case results to chat

|Yes, seamlessly usable as context |Only manually via copy/paste|Only manually via copy/paste
|===

===== RAG & Document Management

|===
|Criterion |{application} |MS Copilot|ChatGPT (Standalone)

|Integrated RAG |Yes, specifically for customer documents|Partially (via M365/SharePoint integration) |Only via separate, technically demanding integrations
|DMS-like document overview |Yes (filter by type, source, content, tags)|Not in this form |No
|Upload new documents by business users| Yes, possible without AI/RAG expertise |Limited, depending on environment |Not without additional infrastructure
|RAG refresh by button|Yes ("Refresh") |No (automated, but less controllable mechanisms)|Not without additional solution
|Delete individual embeddings|Yes ("Delete selected embeddings")|No|No
|Display embeddings per document|Yes, transparency over RAG contents |No |No
|Source reference in answers (top embeddings)|Yes, top 8 embeddings incl. links to the original source|Partially, but less transparent|Only if the prompt is correspondingly designed
|===

===== Automation & Agents

|===
|Criterion |{application} |MS Copilot|ChatGPT (Standalone)

|Comprehensive admin area

|Yes,
ifeval::[{arc-assist} == 1]
audit-specific
endif::[]

|Yes, but generic (M365 Admin Center) | Limited (mainly organizational settings)

|User & role management

|Yes, with
ifeval::[{arc-assist} == 1]
audit-specific
endif::[]
ifeval::[{cgs-assist} == 1]
customer-specific
endif::[]
role logic

|Yes, but not tailored to RAG/customer | Limited (mainly organization vs. user)

|Role-based access to RAG folders

| Yes (for all
ifeval::[{arc-assist} == 1]
encoded audit use cases)
endif::[]
ifeval::[{cgs-assist} == 1]
encoded standard use cases)
endif::[]

|No (prompts decentralized for users) | No (prompts per individual user)

|Configuration of AI providers/LLMs | Yes, incl. API keys for multiple providers | No, primarily Microsoft-owned models | No, tied to OpenAI

|Use case management | Yes (cluster, on/off via toggle, default LLM, roles, rating statistics) | No | No

|License management | Yes (via license file) | Yes (MS license model, but generic) | Yes (account/plan-based, not customer-specific)
|===

===== Maintenance & Ongoing Development

|===
|Criterion |{application} |MS Copilot|ChatGPT (Standalone)

|Development of
ifeval::[{arc-assist} == 1]
audit use cases
endif::[]
ifeval::[{cgs-assist} == 1]
use cases
endif::[]

|Centrally by {author}
ifeval::[{arc-assist} == 1]
and in cooperation with Internal Audit teams
endif::[]

|By customer themselves |By customer themselves

|Ongoing optimization
ifeval::[{arc-assist} == 1]
audit use cases
endif::[]
ifeval::[{cgs-assist} == 1]
use cases
endif::[]

|Yes, centrally and for all customers|Only if customer optimizes internally |Only if customer optimizes internally
|Need for own developers |Not required for standard usage|Often necessary for more complex automations/integrations |Often necessary for integration into processes
|Scale effects| Very high – further developments benefit all customers |Low – each customer optimizes separately |Low – each customer optimizes separately
|===

===== Resilience & Risk Aspects

|===
|Criterion |{application} |MS Copilot|ChatGPT (Standalone)

|Handling of single LLM outages |Fallback to alternative LLMs through multi-provider setup|Dependent on Microsoft / Azure |Dependent on OpenAI
|Reduction of geopolitical risks |Yes, possible by using European/self-hosted models|Limited, US companies|Limited, US companies
|Dependency on a single LLM provider |Low|High |High
|===