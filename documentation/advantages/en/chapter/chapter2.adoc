=== Vendor Independence and LLM Flexibility

*{application}*

* Integration of various LLMs via APIs:
** OpenAI models through Azure AI Foundry
** Models via AWS Bedrock
** Self-hosted open-source models (e.g., European models like Mistral)
* Free choice and switching between models:
** Adaptation to professional requirements (e.g., summarization vs. complex analysis)
** Option to reduce geopolitical risks (e.g., switching to European models)
** Future-proof: It is impossible to predict which model will lead in two years â€“ you stay flexible
* Failover capability: In case of disruptions with one LLM provider, you can quickly switch to another model

*MS Copilot / ChatGPT:*

* Strong ties to the respective vendor and their cloud stack
* In case of outages (e.g., OpenAI / Azure disruptions), the respective tool is not usable. Dependency on US technology models
* Switching to other models is limited or not possible at all; dependency on the vendor's roadmap

[.highlight]#*Value in one sentence:* {application} makes
ifeval::[{arc-assist} == 1]
Internal Audit
endif::[]
ifeval::[{cgs-assist} == 1]
e.g., medium-sized enterprises
endif::[]
independent from any single AI provider and increases both failover capability and strategic flexibility.#

