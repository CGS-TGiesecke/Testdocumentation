
=== Checkliste 

==== LLM-Provider Setup (w채hlen Sie EINEN)

*Option A: Azure OpenAI (empfohlen)*

- [ ] Azure-Abonnement verf체gbar
- [ ] Ressource erstellt
- [ ] Modell deployed (gpt-4o)
- [ ] API-Key + Endpoint notiert

*Option B: AWS Bedrock (gleichwertig)*

- [ ] AWS-Konto verf체gbar
- [ ] Model Access aktiviert
- [ ] IAM-Credentials erstellt
- [ ] Access Keys + Model ID notiert

*Option C: Lokales Modell*

- [ ] GPU-Server bereitgestellt
- [ ] Ollama/vLLM installiert
- [ ] Modell heruntergeladen
- [ ] API-Endpoint getestet

==== Infrastruktur

- [ ] Linux-Server bereitgestellt
- [ ] Docker + Docker Compose installiert
- [ ] SHARED_FOLDER erstellt
- [ ] Firewall-Freigaben (Ports 80, 443)
- [ ] DNS konfiguriert (f체r Caddy)
- [ ] Ausgehende Verbindungen freigegeben
- [ ] Authentifizierungs-Anbindung 
- [ ] SharePoint-Anbindung via Microsoft Entra ID