
include::chapter2-2-llm-advice.adoc[]

*Hinweis:* Azure OpenAI ist unsere bevorzugte Empfehlung, aber AWS Bedrock und lokale Modelle werden gleichwertig unterstützt.

*Wählen Sie einen Provider basierend auf:*

* Vorhandener Cloud-Infrastruktur (Azure oder AWS)
* Datenschutz- und Compliance-Anforderungen
* Budget und Betriebsmodell

*Aufgabe des Kunden:*

* *Azure OpenAI:* Token-Limits in Azure AI Foundry anpassen
* *AWS Bedrock:* Service Quotas in AWS Console prüfen
* *Lokale Modelle:* Ausreichende GPU-Kapazität bereitstellen

==== Übersicht über Modelle

Azure
- https://ai.azure.com/catalog/models

AWS Bedrock
- https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html

==== Kostenübersicht LLM-Provider

*Azure OpenAI (ca., Stand 2026):*

* GPT-4o: $5-15 pro 1M Token
* GPT-4o-mini: $0.15-0.60 pro 1M Token
* *Typisch (50 Nutzer): $100-500/Monat*

*AWS Bedrock (ca., Stand 2026):*

* Claude 3.5 Sonnet: $3-8 pro 1M Input, $15-24 pro 1M Output
* Claude 3 Haiku: $0.25-1 pro 1M Input, $1.25-5 pro 1M Output
* *Typisch (50 Nutzer): $80-400/Monat*

*Lokale Modelle:*

* Keine API-Kosten
* Hardware-Investment: €5.000-50.000+
* Laufende Stromkosten


